https://github.com/HylandKnight/final_project_datavis
# Disclaimer
On my computer this script takes generally about a full thirty seconds to load and about the same to connect to the dash via a web browser. If it starts to take longer than that to load in browser, I've had luck repasting the link in a fresh tab. Please let me know if you have any problems viewing anything.

# Required pip installs:

- EbookLib
- beautifulsoup4
- lxml
- spacy
- networkx
- dash
- dash cytoscape


# Converting from an EPUB to Plain Text with txt_extractor.py

The frist step is to convert an epub file to plain text in order to run our analysis. For this project, I made this part of the code its own file so it could easily be leveraged for future use--all you need to change is the last line to specify which file goes into the function. This code uses the EbookLib library to read in our epub and beautulsoup4 to extract the textual data from the html base using the lxml parser. These libraries will need to be pip installed inside your virtual environment, however this code should also work with python's html.parser. The script extracts text by identifying paragraph elements in the html and joins them together using double newlines in order to preserve paragraph structure. An extra newline is also added after each chapter to separate them more easily. One problem I ran into is that the chapter number is joined without a space to the first word in the chapter title (Chapter 2Kerouac...). I tried tinkering with it but couldn't find a reliable solution, so that would need to be fixed in a future iteration.

# Using NER to identify writers

For this step, I'm leveraging the capabilities of the spacy library to run a name entity recognition on the plain text file containing 'The Greatest Minds of My Generation'. For this, I set up an natural language processor using the pre-trained 'en_core_web_sm' model. Then I set up a function that takes a filepath, processes the text through the nlp, and returns all entities labled 'PERSON' to a list. When I first did this, I ran into several issues. First and foremost, there were multiple instances of the same person being referred to by different names. From what I was able to gather, the simplest solution to this problem is to use the data to create a manual map of entities and name variations in a table that will be applied back into the function. However this could still present a challenge if there are two or more people with a shared name--William S. Buroughs and William Carlos Williams, for instance.

To help aleviete this, I decided to limit the graph to the top 27 most common occurences of each writer. This ensures that each occurence referenced in the graph was mentioned in the book over five times, which avoids including any minor figures casually referenced by Ginsberg. It also makes the process of constructing the map more manageable and faster to weed out potential inconsistencies. I first returned the top 50 most common name occurences and used that list as the basis for my map, adding name combinations so that further returns yielded each entity's first and last names. In instances where a named entity seemingly did not refer to any kind of writer or otherwise relevant figure (ie. 'Cody' referring to the book 'Visions of Cody'), I excluded them manually from the data. Determining this often came down to quereying my pre-existing epub for given entity references, and adding the most sensible combinations of a given name to the map while avoiding as many cases of mistaken identity as possible. However this still doesn't account for the presence of other historical writers like Dostoevsky or Thomas Wolfe, who, while not themselves Beat writers, held a certain influence over members of the generation. For the context of this graph, which seeks to better understand the community of the Beats through their connections, I decied to leave these other writers in as a means of showcasing the scope their influence may have had over multiple writers.

Overall, this is by no means a perfect solution, as I'm sure some unintended entities will slip through the cracks, but the map should dramatically improve the integrity of the network. Thus, it should be noted that because of the manual nature of this step, any attempts by users to replicate this process should treat their own data contextually to employ the most sensible cleaning tactics.

# Identifying co-occurances

Now the text gets broken down again by the nlp at the sentence level to yield co-occurrences of two writers in the same sentence, the number of which is stored in a counter object. The combinations method from the intertools library is used to keep track of different co-occurances in a given sentence--if three writers are referenced in the same sentence, all combinations of two are passed to the counter. For this project, keeping the analysis on the sentence level seemed to make the most sense. However, it's important to remember that these connections are based purely on spatial proximity in the text--a semantic analysis has not been implemented. The logic is that if Ginsberg includes the same writers in the same sentences often, for whatever reason, then that implies association.

Networkx is called to form a graph to represent these co-occurances where nodes are writers and edges are weighted based on number of co-occurrances. When we print the number of nodes, however, we only have 13--far less than the 27 we started with. This is likely due to the remaining 14 writers not occuring in the same sentence as other writers, which highlights a potential weakness in my methodology. If a writer occurs in a sentence with a pronoun such as "he" or "she", they won't trigger a co-occurrence that might otherwise have been present. For this reason, it might be useful to create an alternate graph that shows co-occurences by paragraph.

# Visualization and data interpretation

After messing around with a few different versions of graph options generated by ChatGPT, I decided to move forward with a Cytoscape Dash app becasue of the way it lets you move nodes around freely. After I learned how to convert my netowrkx graph to cytoscape, I mainly relied on the documentation (https://dash.plotly.com/cytoscape) to provide starting templates that I could work from. The first thing I changed was the layout to 'cose' which arranges the graph by the weighted edges, which felt the most natural. I also figured out how to make a style sheet, which comes in the form of a dictionary that lets you use another dictionary as a key for node and edge styling. I was able to change the width of nodes to make them look nicer in a graph, but I couldn't figure out how to add hover. I couldn't find anything solid online about it, so I probed ChatGPT a bit and after some back and forth with some ideas that didn't work, it gave me a kind of janky version of hover that leveraged dash.dependancies where the hover data appears in the corner of the screen. Right now, it only tells you the name of the node, and the edge relationship you're on, but in a futre graph, perhaps more useful data could be made availible here. These input/output fields are called at the end of the script before the app is built. Finally, I also got it to give me a way to change the color of certain nodes to represent the non-beat writers in the network, which required me to list all the non-beat writers inside a variable that was used in the middle of the style sheet. Overall, this graph reveals to us a close-knit 'core' group of writers, the most popular of which (at least from the restrospective view of Ginsberg) include Kerouac, Holmes, and Corso.

Given the lack of nodes due to the sentence-level analysis, I decided to use my second graph to explore a paragraph-level analysis. This meant that I had to retool part of my script to include a few additional functions that would acomodate these co-occurances, but otherwuse I was able to reuse much of the same code to do it. With the new graph, we can see (a few) more of those top 27 I had identified earlier on in the script. This broadened the scope of the network somewhat, which meant that we were both able to see writers that were frequently mentioned against one another in the first graph, and then see how some additional writers fit into that network as we pulled out. One of the surpises was Lucien Carr's lack of connections especially to the younger grouping of writers. He only gets a connection to Burroughs and to Wolfe--although this may also be explained by him appearing in more sentences that refer to other writers with pronouns. That, in itself, however, might indicate that he's more frequently mentioned alongside only one other writer at a time. Perhaps more curiously is the lack of some of the other mentions from the NER like Shakespeare or Dostoevsky, who according to the data did not apear in any paragraphs with other writers. This might warrant some future scruitiny to determine whether they are accidently being passed over in the code. 

There is some novelty in tracking the relationships here, especially between red and blue nodes. Because of the nature of the data it might be hard to conclusively determine if any influence between writers occured, however it could be used as a point of curiousity for close readings or perhaps further distant textual analyses like stylometry. Either way, although the visualization itself is interesting to parse through, it does not stand on its own to provide any specific insight--rather I view it as a jumping off point for supplementary research.